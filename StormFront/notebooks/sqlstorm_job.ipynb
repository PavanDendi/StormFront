{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"7d29fc8e-0d16-4907-8a42-1af721b43796","showTitle":false,"title":""}},"outputs":[],"source":["from StormFront import app, CONTEXT, CONTEXT_RAW\n","from StormFront.utils import *\n","from pprint import pprint\n","\n","tw = dbutils.widgets.text\n","dw = dbutils.widgets.dropdown\n","dwg = dbutils.widgets.get\n","\n","tw('database_name', 'default', 'Database Name')\n","tw('sql_folder', f'/Workspace/Repos/{CONTEXT.user}/dUI/queries/tpcds_2.13', 'SQL Folder')\n","tw('host', CONTEXT.host, 'API Hostname')\n","tw('tscope', '', 'Token Scope')\n","tw('tkey', '', 'Token key')\n","\n","tw('cluster_id', '', 'SQL Endpoint ID')\n","\n","csizes = ['2X-Small', 'X-Small', 'Small', 'Medium', 'Large', 'X-Large', '2X-Large', '3X-Large', '4X-Large']\n","dw('Size', 'Medium', csizes)\n","tw('clusters_min', '1', 'Min Clusters')\n","tw('clusters_max', '1', 'Max Clusters')\n","dw('Serverless', 'False', ['True', 'False'])\n","dw('Channel', 'Current', ['Current', 'Preview'])\n","\n","# dbutils.widgets.text('parallel_conn','5','Parallel Connections')\n","# dbutils.widgets.text('re_peats','10','Query Repeats')"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"f6e26408-c727-4e86-8ec4-a3657e07f98a","showTitle":false,"title":""}},"outputs":[{"data":{"text/plain":["Token retrieval success\n","Creating SQL Endpoint\n","new cluster_id: 4d1313e2cc28cad2\n","ntuple(id='4d1313e2cc28cad2', name='Storm Cloud', size='MEDIUM', cluster_size='Medium', min_num_clusters=1, max_num_clusters=1, auto_stop_mins=15, auto_resume=True, creator_name='pavan.dendi@databricks.com', creator_id=8008172456975791, tags=tags(), spot_instance_policy='COST_OPTIMIZED', enable_photon=True, channel=channel(name='CHANNEL_NAME_CURRENT'), enable_serverless_compute=False, num_clusters=0, num_active_sessions=0, state='STARTING', jdbc_url='jdbc:spark://adb-2290777133481849.9.azuredatabricks.net:443/default;transportMode=http;ssl=1;AuthMech=3;httpPath=/sql/1.0/endpoints/4d1313e2cc28cad2;', odbc_params=odbc_params(hostname='adb-2290777133481849.9.azuredatabricks.net', path='/sql/1.0/endpoints/4d1313e2cc28cad2', protocol='https', port=443), health=health(status='HEALTHY'))\n"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"Token retrieval success\nCreating SQL Endpoint\nnew cluster_id: 4d1313e2cc28cad2\nntuple(id='4d1313e2cc28cad2', name='Storm Cloud', size='MEDIUM', cluster_size='Medium', min_num_clusters=1, max_num_clusters=1, auto_stop_mins=15, auto_resume=True, creator_name='pavan.dendi@databricks.com', creator_id=8008172456975791, tags=tags(), spot_instance_policy='COST_OPTIMIZED', enable_photon=True, channel=channel(name='CHANNEL_NAME_CURRENT'), enable_serverless_compute=False, num_clusters=0, num_active_sessions=0, state='STARTING', jdbc_url='jdbc:spark://adb-2290777133481849.9.azuredatabricks.net:443/default;transportMode=http;ssl=1;AuthMech=3;httpPath=/sql/1.0/endpoints/4d1313e2cc28cad2;', odbc_params=odbc_params(hostname='adb-2290777133481849.9.azuredatabricks.net', path='/sql/1.0/endpoints/4d1313e2cc28cad2', protocol='https', port=443), health=health(status='HEALTHY'))\n","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"ansi"}},"output_type":"display_data"}],"source":["database = dwg('database_name')\n","sql_dir = dwg('sql_folder')\n","host = dwg('host')\n","# token = CONTEXT_RAW['extraContext']['api_token']\n","\n","try:\n","    token = dbutils.secrets.get(scope=dwg('tscope'), key=dwg('tkey'))\n","    print(f\"Token retrieval success\")\n","except BaseException as e:\n","    print(\"Something went wrong retrieving PA token.\")\n","    print(\"PAT required in order to use sqlstorm.\")\n","    print(e)\n","\n","if (cluster_id := dwg('cluster_id')) == '':\n","    print('Creating SQL Endpoint')\n","    ep_cfg = EndpointCfg(\n","        size=dwg('Size'),\n","        clusters_min=dwg('clusters_min'),\n","        clusters_max=dwg('clusters_max'),\n","        serverless=True if dwg('Serverless') == 'True' else False,\n","        channel=\"CHANNEL_NAME_CURRENT\" if dwg('Channel') == 'Current' else \"CHANNEL_NAME_PREVIEW\"\n","    )\n","    cluster_id = create_ep(token, host, ep_cfg)\n","\n","ep_details = get_or_del_ep(token, host, cluster_id)\n","pprint(ep_details)\n","  \n","\n","# parallel_conn = dbutils.widgets.get('parallel_conn')\n","# re_peats = dbutils.widgets.get('re_peats')"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"c15ef8b1-be0d-49ad-9f40-a1e65e4d2498","showTitle":false,"title":""}},"outputs":[{"data":{"text/plain":["Writing yaml config file to: /dbfs/tmp/dbstress/config.yaml\n","---\n","unit_name: test\n","query: \"/* test  @@gen_query_id@@ */\n","SELECT 1\"\n","uri: \"jdbc:spark://adb-2290777133481849.9.azuredatabricks.net:443/{database};transportMode=http;ssl=1;AuthMech=3;httpPath=/sql/1.0/endpoints/4d1313e2cc28cad2;UID=token;PWD=[REDACTED];UseNativeQuery=1\"\n","driver_class: com.simba.spark.jdbc.Driver\n","username: username\n","password: password\n","parallel_connections: 1\n","repeats: 1\n","connection_timeout: 3000\n","\n"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"Writing yaml config file to: /dbfs/tmp/dbstress/config.yaml\n---\nunit_name: test\nquery: \"/* test  @@gen_query_id@@ */\nSELECT 1\"\nuri: \"jdbc:spark://adb-2290777133481849.9.azuredatabricks.net:443/{database};transportMode=http;ssl=1;AuthMech=3;httpPath=/sql/1.0/endpoints/4d1313e2cc28cad2;UID=token;PWD=[REDACTED];UseNativeQuery=1\"\ndriver_class: com.simba.spark.jdbc.Driver\nusername: username\npassword: password\nparallel_connections: 1\nrepeats: 1\nconnection_timeout: 3000\n\n","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"ansi"}},"output_type":"display_data"}],"source":["# from dUI import dUI\n","jdbc = simba_jdbc(token, ep_details.odbc_params)\n","query_test = Query(\"test\", \"SELECT 1\")\n","# queries = utils.read_sql_folder(sql_dir, info=True)\n","app.run(jdbc, [query_test])"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"0d6cad3f-20e5-46c3-b99f-14ef8ceb2b88","showTitle":false,"title":""}},"outputs":[{"data":{"text/plain":["4d1313e2cc28cad2\n","{}\n"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"4d1313e2cc28cad2\n{}\n","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"ansi"}},"output_type":"display_data"}],"source":["# host = \"adb-2290777133481849.9.azuredatabricks.net\"\n","# cluster_id = \"fe5412cd68e9d437\"\n","# token = context.extraContext.api_token\n","# apiurl = f\"https://{host}/api/2.0/sql/endpoints/\"\n","# headers = {\"Authorization\": f\"Bearer {token}\"}\n","# response = requests.delete(apiurl+cluster_id, headers=headers).json()\n","print(cluster_id)\n","response = get_or_del_ep(token, host, cluster_id, delete=True)\n","pprint(response)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"e973fbc3-6dfa-46a6-8c4a-b7e38a4a1747","showTitle":false,"title":""}},"outputs":[],"source":["dbutils.widgets.removeAll()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"79a7d62d-f5d7-4c6e-8be7-350660217a4b","showTitle":false,"title":""}},"outputs":[],"source":[]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":2,"widgetLayout":[]},"notebookName":"sqlâš¡torm_job","notebookOrigID":2368490112402136,"widgets":{}},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
